<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0"><channel><title>Data Science Challenge / Competition</title><link>https://iphysresearch.github.io/DataSciComp</link><description>Latest update at 07/23/2019 (GMT+0800).</description><item><title>NeurIPS 2019: Disentanglement Challenge</title><link>https://www.aicrowd.com/challenges/neurips-2019-disentanglement-challenge</link><category>PF/AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Given the growing importance of the field and the potential societal impact in the medical domain or fair decision making, it is high time to bring disentanglement to the real-world: Stage 1: Sim-to-real transfer learning - design representation learning algorithms on simulated data and transfer them to the real world. Stage 2: Advancing disentangled representation learning to complicated physical objects.</description></item><item><title>Snake Species Identification Challenge</title><link>https://www.aicrowd.com/challenges/snake-species-identification-challenge#timeline</link><category>PF</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>In this challenge you will be provided with a dataset of RGB images of snakes, and their corresponding species (class). The goal is to train a classification model.</description></item><item><title>2019百度之星开发者大赛</title><link>https://aistudio.baidu.com/aistudio/competition/detail/7</link><category>PF</category><category>CV/NLP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>本次竞赛任务为目标检测，参赛者需要找出所给图像中所有感兴趣的目标，确定它们的位置和大小。参赛者需提供一个飞桨（PaddlePaddle）模型，模型输出所给图片中每个目标的信息，包括boundingbox（[x0,y0,x1,y1]）、类别信息和分数。</description></item><item><title>2019 AIIA杯人工智能巡回赛 中国移动“家·网”赛站</title><link>http://aiia.cmri.cn</link><category>PF</category><category>CV/DM</category><pubDate>Tue, 23 Jul 2019</pubDate><description>结合中国移动在AI领域的研发布局，本次“家·网”赛站的主题是智慧家庭和智慧网络，希望借助AI技术构建数字家庭生态，打造动态高效的智能网络。 <a href="http://open.home.10086.cn/hack/#/protal">智慧家庭赛题</a> <a href="http://aiia.cmri.cn/index/content_page">智慧网络赛题</a>: 任务一：网络流量预测; 任务二：无线侧故障根因分析; </description></item><item><title>中文场景文字识别技术创新大赛</title><link>https://aistudio.baidu.com/aistudio/competition/detail/8</link><category>PF</category><category>CV/NLP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>文字识别的主要任务是对图像区域中的文字行进行预测，返回文字行的内容。</description></item><item><title>Reconnaissance Blind Chess</title><link>https://rbc.jhuapl.edu</link><category>AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Build the best AI bot to play reconnaissance blind chess, a challenge for making optimal decisions in the face of uncertainty. Reconnaissance blind chess is like chess except a player does not know where her opponent's pieces are a priori. Rather, she can covertly sense a chosen 3x3 square of the board each turn and also learn partial information from captures.</description></item><item><title>The VoxCeleb Speaker Recognition Challenge</title><link>http://www.robots.ox.ac.uk/~vgg/data/voxceleb/competition.html</link><category>PF/AC</category><category>SP/CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>The goal of this challenge is to probe how well current methods can recognize speakers from speech obtained 'in the wild'. The challenge will consists of the following two tasks: Audio only speaker verification - Fixed training data: This task requires that participants train only on the VoxCeleb2 dev dataset for which we have already released speaker verification labels. The dev dataset contains 1,092,009 utterances from 5,994 speakers. Audio only speaker verification - Open training data: For the open training condition, participants can use the VoxCeleb datasets and any other data (including that which is not publicly released) except the challenge's test data</description></item><item><title>Dunhuang Image Restoration Challenge@ICCV2019 workshop on e-Heritage</title><link>http://www.eheritage-ws.org</link><category>PF/AC</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>In 1970s, the Dunhuang Academy is established to systematically preserve the heritage. From the study, half of them suffer from corrosion and aging. Because the paintings are created by different artists from 10 centuries, it is non-trivial for manual restoration. And therefore, we release the first Dunhuang Challenge with 600 paintings, which enables an open and public attention in the research community on data driven e-heritage restoration. This year, the academy is proposing to collaborate with Microsoft Research and other researchers over the world, aiming to solve the automatic restoration of the wall painting using computer vision and machine learning technology.</description></item><item><title>阿里巴巴大数据智能云上编程大赛 —— 智联招聘人岗智能匹配</title><link>https://tianchi.aliyun.com/competition/entrance/231728/introduction</link><category>PF</category><category>DM</category><pubDate>Tue, 23 Jul 2019</pubDate><description>本次大赛要求参赛者根据智联招聘抽样的经过脱敏的求职者标签数据、职位信息、及部分求职者行为信息、用人单位反馈信息，训练排序模型，对求职者的职位候选集进行排序，尽可能使得双端都满意的职位（求职者满意以及用人单位满意）优先推荐。本次比赛里，假定对于曝光给求职者的职位候选集里，假如求职者感兴趣会产生浏览职位行为，浏览职位后，如果求职者满意会产生主动投递行为。用人单位收到求职者主动投递的简历后会给出是否满意的反馈信号。</description></item><item><title>Accurate Automated Spinal Curvature Estimation</title><link>https://aasce19.grand-challenge.org</link><category>PF/AC</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>The goal of MICCAI 2019 Challenge on accurate automated spinal curvature estimation and error correction from x-ray images is to investigate (semi-)automatic spinal curvature estimation algorithms and provide a standard evaluation framework with a set of x-ray images. </description></item><item><title>AIM 2019 image manipulation challenges</title><link>http://www.vision.ee.ethz.ch/aim19/</link><category>PF/AC</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Advances in Image Manipulation workshop and challenges on image and video manipulation in conjunction with ICCV 2019. AIM 2019 image manipulation challenges: <a href="https://competitions.codalab.org/competitions/20156">Bokeh Effect Challenge: Track 1 Fidelity</a>; <a href="https://competitions.codalab.org/competitions/20157">Bokeh Effect Challenge: Track 2 Perceptual</a>; <a href="https://competitions.codalab.org/competitions/20158">RAW-to-RGB Mapping Challenge: Track 1 Fidelity</a>; <a href="https://competitions.codalab.org/competitions/20159">RAW-to-RGB Mapping Challenge: Track 2 Perceptual</a>; <a href="https://competitions.codalab.org/competitions/20163">Real World Super-Resolution Challenge: Track 1 Same Domain</a>; <a href="https://competitions.codalab.org/competitions/20164">Real World Super-Resolution Challenge: Track 2 Target Domain</a>; <a href="https://competitions.codalab.org/competitions/20165">Demoireing Challenge: Track 1 Fidelity</a>; <a href="https://competitions.codalab.org/competitions/20166">Demoireing Challenge: Track 2 Perceptual</a>; <a href="https://competitions.codalab.org/competitions/20167">Constrained Super-Resolution Challenge: Track 1 Parameters optimization</a>; <a href="https://competitions.codalab.org/competitions/20168">Constrained Super-Resolution Challenge: Track 2 Inference optimization</a>; <a href="https://competitions.codalab.org/competitions/20169">Constrained Super-Resolution Challenge: Track 3 Fidelity optimization</a>; <a href="https://competitions.codalab.org/competitions/20235">Extreme Super-Resolution Challenge: Track 1 Fidelity</a>; <a href="https://competitions.codalab.org/competitions/20236">Extreme Super-Resolution Challenge: Track 2 Perceptual</a>; AIM 2019 video manipulation challenges: <a href="https://competitions.codalab.org/competitions/20246">Video Quality Mapping Challenge : Track 1 Supervised</a>; <a href="https://competitions.codalab.org/competitions/20247">Video Quality Mapping Challenge : Track 2 Unsupervised</a>; <a href="https://competitions.codalab.org/competitions/20248">Video Extreme Super-Resolution Challenge: Track 1 Fidelity</a>; <a href="https://competitions.codalab.org/competitions/20249">Video Extreme Super-Resolution Challenge: Track 2 Perceptual</a>; <a href="https://competitions.codalab.org/competitions/20244">Video Temporal Super-Resolution Challenge</a>; </description></item><item><title>Game of Drones – Competition at NeurIPS 2019</title><link>https://www.microsoft.com/en-us/research/academic-program/game-of-drones-competition-at-neurips-2019/</link><category>AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Game of Drones is a multi-drone racing tournament conducted in the high-fidelity simulation environment AirSim. Participants will have the choice of three tiers: Planning only, Perception only, or Full Autonomous Racing. The aim is to combine challenges from adversarial planning and real-time perception and to encourage fusing learning- and model-based approaches.</description></item><item><title>2019之江杯全球人工智能大赛</title><link>http://aicup2019.zhejianglab.com</link><category>PF</category><category>CV/DM/NLP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>随着新一轮世界科技革命和产业变革的孕育兴起，人工智能已经成为当前信息技术和未来科技高端发展的重要方向。为激发广大科研人员人工智能创业者参与人工智能前沿理论和算法研究的热情，之江实验室举办2019之江杯全球人工智能大赛，以“以赛引才、以赛促研、以赛兴业”为基本思路，聚焦人工智能“基础研究”+“产融结合”，促进我国人工智能发展走在世界前列引领科技发展潮流。 <a href="https://zhejianglab.aliyun.com/entrance/231734/introduction?spm=5176.12281949.1003.1.2b58c341xkeLkZ">视频描述生成</a>: 本赛题为视频描述（Video Caption）,视频描述的输入是一段视频，输出是描述视频主要故事的一段文本。 <a href="https://zhejianglab.aliyun.com/entrance/231733/introduction?spm=5176.12281949.1003.2.2b58c341xkeLkZ">行人多目标跟踪</a>: 主要任务是给定一个图像序列，找到图像序列中运动的物体，对目标进行定位，并将不同帧中的同一行人一一对应，记录其ID，然后给出不同物体的运动轨迹。 <a href="https://zhejianglab.aliyun.com/entrance/231732/introduction?spm=5176.12281949.1003.3.2b58c341xkeLkZ">零样本目标检测</a>: 零样本目标检测（zero-shot object detection）竞赛的任务是在已知类别上训练目标检测模型，但要求模型能够用于检测测试图片中未知类别的对象。 <a href="https://zhejianglab.aliyun.com/entrance/231731/introduction?spm=5176.12281949.1003.4.2b58c341xkeLkZ">电商评论观点挖掘</a>: 本次品牌评论观点挖掘的任务是在商品评论中抽取商品属性特征和消费者观点，并确认其情感极性和属性种类。 </description></item><item><title>NeurIPS 2019 : MineRL Competition</title><link>https://www.aicrowd.com/challenges/neurips-2019-minerl-competition</link><category>PF/AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>The main task of the competition is solving the ObtainDiamond environment. In this environment, the agent begins in a random starting location without any items, and is tasked with obtaining a diamond. This task can only be accomplished by navigating the complex item hierarchy of Minecraft.</description></item><item><title>IEEE-CIS Fraud Detection</title><link>https://www.kaggle.com/c/ieee-fraud-detection</link><category>PF/AC</category><category>DM</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Can you detect fraud from customer transactions?</description></item><item><title>Open Images 2019 - Instance Segmentation</title><link>https://www.kaggle.com/c/open-images-2019-instance-segmentation</link><category>PF/AC</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Outline segmentation masks of objects in images</description></item><item><title>全球数据资源开发者大赛</title><link>https://wdd.datarda.com/index</link><category>PF</category><category>DM</category><pubDate>Tue, 23 Jul 2019</pubDate><description> 中国移动专题赛: 赛题一：ETC便民服务群体挖掘; 赛题二：企业人才结构变化预测; 行业算法赛: 赛题一：楼盘精准推荐模型; 赛题二：社区独居老人识别与居民用能数据分析; 赛题三：移动办事服务的用户行为预测; </description></item><item><title>Kuzushiji Recognition</title><link>https://www.kaggle.com/c/kuzushiji-recognition</link><category>PF/AC</category><category>NLP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Opening the door to a thousand years of Japanese culture</description></item><item><title>NeurIPS 2019: Learn to Move - Walk Around</title><link>http://osim-rl.stanford.edu/docs/nips2019/</link><category>PF/AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>You are provided with a human musculoskeletal model and a physics-based simulation environment, OpenSim. There will be three tracks: 1) Best performance, 2) Novel ML solution, and 3) Novel biomechanical solution, where all the winners of each track will be awarded.</description></item><item><title>Traffic4cast -- Traffic Map Movie Forecasting</title><link>https://www.iarai.ac.at/traffic4cast/</link><category>AC</category><category>CV</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Predict high resolution traffic flow volume, heading, and speed on a whole city map looking 15 minutes into the future! Kicking off a series of annual competitions, this year's data is based on 100 billion probe points from 3 cities mapped in 5 minute intervals, showing trends across weekdays and seasonal effects. Improved traffic predictions are of great social, environmental, and economic value, while also advancing our general ability to capture the simple implicit rules underlying a complex system and model its future states.</description></item><item><title>Causality for Climate (C4C)</title><link>https://causeme.uv.es</link><category>AC</category><category>CV/SP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>A causal understanding of climatic interactions is of high societal relevance from identifying causes of extreme events to process understanding and weather forecasting. This competition comprises a number of multivariate time series datasets featuring major challenges of climate data from time delays and nonlinearity to nonstationarity and selection bias. The competition aims to open up new interdisciplinary research pathways by improving our scientific understanding of Earth’s climate, while also driving method development and benchmarking in the computer science community.</description></item><item><title>Automated Deep Learning (AutoDL)</title><link>https://autodl.chalearn.org</link><category>AC</category><category>CV/SP/DM/NLP/RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>The AutoDL challenge aims taking the automate the design of deep learning (DL) methods to solve generic tasks. This is a challenge with “code submission”: machine learning algorithms are trained and tested on a challenge platform on data invisible to the participants. We target applications such as speech, image, video, and text, for which DL methods have had great success recently, to drive the community to work on automating the design of DL models. Raw data will be provided, formatted in a uniform tensor manner, to encourage participants to submit generic algorithms. We will impose restrictions on training time and resources to push the state-of-the-art further. We will provide a large number of pre-formatted public datasets and set up a repository of data exchange to enable meta-learning.</description></item><item><title>Animal-AI Olympics Competition</title><link>http://animalaiolympics.com</link><category>PF/AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>The Animal-AI Olympics is an AI competition with tests inspired by animal cognition. Participants are given a small environment with just seven different classes of objects that can be placed inside. In each test, the agent needs to retrieve the food in the environment, but to do so there are obstacles to overcome, ramps to climb, boxes to push, and areas that must be avoided. The real challenge is that we don't provide the tests in advance. It's up to you to play with the environment and build interesting setups that can help create an agent that understands how the environment's physics work and the affordances that it has. The final submission should be an agent capable of robust food retrieval behaviour similar to that of many kinds of animals. We know the animals can pass these tests, it's time to see if AI can too. The Animal-AI Olympics is an AI competition with tests inspired by animal cognition. Participants are given a small environment with just seven different classes of objects that can be placed inside. In each test, the agent needs to retrieve the food in the environment, but to do so there are obstacles to overcome, ramps to climb, boxes to push, and areas that must be avoided. The real challenge is that we don't provide the tests in advance. It's up to you to play with the environment and build interesting setups that can help create an agent that understands how the environment's physics work and the affordances that it has. The final submission should be an agent capable of robust food retrieval behaviour similar to that of many kinds of animals. We know the animals can pass these tests, it's time to see if AI can too. </description></item><item><title>3D Object Detection over HD Maps for Autonomous Cars</title><link>https://level5.lyft.com/dataset/</link><category>AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Autonomous cars are expected to dramatically redefine the future of transportation. The 3D Perception system of the autonomous car is a critical keystone upon which high level autonomy functions depend. This competition is designed to help advance the state of the art in 3D object detection by focusing research on this topic in the context of autonomous cars, specifically by sharing the full modality of sensor data available to typical autonomous cars, and by providing access to a high fidelity HD map.</description></item><item><title>Pommerman Year 2: Radio.</title><link>https://www.pommerman.com</link><category>AC</category><category>RL</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Pommerman: Train a team of communicative agents to play Bomberman in a partially observed setting. Compete against other teams.</description></item><item><title>Live Malaria Challenge</title><link>https://researcher.watson.ibm.com/researcher/view_group.php?id=9784</link><category>AC</category><category>DM</category><pubDate>Tue, 23 Jul 2019</pubDate><description>In the NeurIPS Live Malaria Challenge we are looking for participants to apply machine learning tools to determine novel solutions which could impact malaria policy in Sub Saharan Africa. Specifically, how should combinations of interventions be deployed under budget constraints to impact lives saved and the prevalence of the malaria parasite in a simulated environment.</description></item><item><title>TweetQA Competition</title><link>https://tweetqa.github.io</link><category>PF/AC</category><category>NLP</category><pubDate>Tue, 23 Jul 2019</pubDate><description>Unlike other QA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. The task requires model to read a short tweet and a question and outputs a text phrase (does not need to be in the tweet) as the answer.</description></item><item><title>"华为云杯"2019深圳开放数据应用创新大赛</title><link>https://opendata.sz.gov.cn/sodic2019/</link><category>PF</category><category>CV/DM/NLP</category><pubDate>Sat, 06 Jul 2019</pubDate><description> 赛题数据： 交通数据 室内停车 公租房轮候 卫星遥感 文体公益活动 游客预约 道路积水 深圳图书馆进馆人次统计 龙岗区坂田街道交通流量 企业信用目录 坪山区民生诉求数据 坪山区河流域和易积水道路视频 光明区政府服务办事大厅预约</description></item><item><title>莱斯杯：全国第二届“军事智能机器阅读"挑战赛"</title><link>https://www.kesci.com/home/competition/5d142d8cbb14e6002c04e14a</link><category>PF</category><category>NLP</category><pubDate>Sat, 06 Jul 2019</pubDate><description>本次竞赛提供的大规模中文阅读理解数据集，共包含15万余篇的专业文章，7万个军事类复杂问题，每个问题对应五篇文章</description></item><item><title>“添翼杯”人工智能创新应用大赛</title><link>https://tianyicup.kesci.com</link><category>PF</category><category>CV/DM</category><pubDate>Sat, 06 Jul 2019</pubDate><description> 智慧环保-垃圾分类图像检测问题: 请参赛选手利用训练集图片，建立算法模型，对测试集给定的物品图片，判断其属于可回收垃圾的概率。 智慧教育-成绩预测问题：请参赛选手利用脱敏后的初中学生过往考试情况与考试考点信息，建立算法模型，预测学生初中最后一次期末考试的成绩。</description></item><item><title>Generative Dog Images</title><link>https://www.kaggle.com/c/generative-dog-images</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>Experiment with creating puppy pics</description></item><item><title>2nd 3D Face Alignment in the Wild Challenge - Dense Reconstruction from Video</title><link>https://competitions.codalab.org/competitions/23626</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>The 2nd 3DFAW Challenge evaluates 3D face reconstruction methods on a new large corpora of profile-to-profile face videos annotated with corresponding high-resolution 3D ground truth meshes. The corpora includes profile-to-profile videos obtained under a range of conditions: high-definition in-the-lab video, unconstrained video from an iPhone device</description></item><item><title>AutoCV2: Image and video Classification</title><link>https://autodl.lri.fr/competitions/146</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>This is round 2 of AutoCV: Image + Video! This is a 2-phase challenge, see the challenge rules for details. This is the FEED-BACK PHASE. The second phase (final blind-test phase) will be run from a separate submission site, to be announced after the end of the feed-back phase.</description></item><item><title>APTOS 2019 Blindness Detection</title><link>https://www.kaggle.com/c/aptos2019-blindness-detection</link><category>PF</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>Detect diabetic retinopathy to stop blindness before it's too late</description></item><item><title>QMUL Surveillance Face Recognition Challenge @ ICCV2019 workshop RLQ</title><link>https://qmul-survface.github.io</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>The challenge data consists of a set of popular search queries and a fair size set of candidate documents. Challenge participants make a boolean relevant-or-not decision for each query-document pair. Human judgments are used to create labeled training and evaluation data for a subset of the query-document pairs. Evaluation of submissions will be based on the traditional F1 metric, incorporating components of both recall and precision.</description></item><item><title>“达观杯”文本智能信息抽取挑战赛</title><link>https://www.biendata.com/competition/datagrand/</link><category>PF</category><category>NLP</category><pubDate>Sat, 06 Jul 2019</pubDate><description>本次大赛的任务是给定一定数量的标注语料以及海量的未标注语料，在3个字段上做信息抽取任务。</description></item><item><title>CoNLL 2019 Shard Task on Cross-Framework Meaning Representation Parsing</title><link>http://mrp.nlpl.eu</link><category>PF/AC</category><category>DM/NLP</category><pubDate>Sat, 06 Jul 2019</pubDate><description>The 2019 Conference on Computational Language Learning (CoNLL) hosts a shared task (or ‘system bake-off’) on Cross-Framework Meaning Representation Parsing (MRP 2019). The goal of the task is to advance data-driven parsing into graph-structured representations of sentence meaning. </description></item><item><title>The 3rd YouTube-8M Video Understanding Challenge</title><link>https://www.kaggle.com/c/youtube8m-2019</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>Temporal localization of topics within video</description></item><item><title>AI in RTC-超分辨率图像质量比较挑战赛</title><link>https://www.dcjingsai.com/common/cmpt/AI%20in%20RTC-超分辨率图像质量比较挑战赛_竞赛信息.html</link><category>PF</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>单帧图像超分辨率近年来备受关注。同样的图像，在经过不同超分辨率算法处理后，获得的图像质量也有所不同。在这个挑战中，参赛者需要对100张图片进行4倍超分辨率处理。比赛最终以PI (perceptual index)指标作为评判标准，PI值越小，表明图像质量越高，得分越高，分值高的团队获得优胜。</description></item><item><title>AI in RTC-超分辨率算法性能比较挑战赛</title><link>https://www.dcjingsai.com/common/cmpt/AI%20in%20RTC-超分辨率算法性能比较挑战赛_竞赛信息.html</link><category>PF</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>将超分辨算法用于处理实时视频流时，模型的处理表现与运算性能，是一个两难的选择。为了追求较低复杂度，可能需要牺牲图像质量；为了追求较高质量的输出，导致设备资源占用过高，产生设备发烫、视频模糊卡顿等现象。该挑战主要考察算法模型的性能，参赛者需要对图像做2倍的超分辨率处理，算法复杂度控制在1GFLOPs之内，我们以SRCNN模型为baseline, 并采用PSNR、SSIM及运行时间来综合评估算法的性能，分值高者即获胜。</description></item><item><title>EPIC-Kitchens Action Anticipation</title><link>https://competitions.codalab.org/competitions/20115</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 06 Jul 2019</pubDate><description>The <b>largest dataset in first-person (egocentric) vision</b>; multi-faceted <b>non-scripted</b> recordings in native environments - i.e. the wearers' homes, capturing all daily activities in the kitchen over multiple days. <a href='https://competitions.codalab.org/competitions/20115'>Action-Recognition Challenge</a> <a href='https://competitions.codalab.org/competitions/20071'>Action-Anticipation Challenge</a> <a href='https://competitions.codalab.org/competitions/20111'>Object-Detection Challenge</a></description></item><item><title>Lexical Semantic Change Detection in German</title><link>https://competitions.codalab.org/competitions/23563</link><category>PF/AC</category><category>NLP</category><pubDate>Sat, 06 Jul 2019</pubDate><description>Given two corpora Ca and Cb, rank all target words according to their degree of lexical semantic change between Ca and Cb as annotated by human judges. (Higher rank means higher change.)</description></item></channel></rss>