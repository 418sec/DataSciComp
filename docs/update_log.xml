<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0"><channel><title>Data Science Challenge / Competition</title><link>https://iphysresearch.github.io/DataSciComp</link><description>Latest update at 05/06/2019 (GMT+0800).</description><item><title>Objects 365 图片物体检测</title><link>https://www.biendata.com/competition/objects365/</link><category>PF</category><category>CV</category><pubDate>Mon, 06 May 2019</pubDate><description>Objects365是一个全新的数据集，旨在促进对自然场景不同对象的检测研究。Objects365在638K张图像上标注了365个对象类，训练集中共有超过1000万个边界框。因此，这些标注涵盖了发生在各种场景类别中的常见对象。</description></item><item><title>Crowd Human 人体检测</title><link>https://www.biendata.com/competition/crowdhuman/</link><category>PF</category><category>CV</category><pubDate>Mon, 06 May 2019</pubDate><description>CrowdHuman是目前最大的人体检测数据集，带有充分的标注信息，图片来源具有丰富的多样性。包含15000张训练集，4370张验证集和5000张测试集，在数据集中，总共有340K个人体目标，平均每张图片有22.6个人，数据集中有各种各样的遮挡场景。每个人的实例都有一个头部边界框、可见区域边界框和全身边界框。</description></item><item><title>2019中国高校计算机大赛——大数据挑战赛</title><link>https://www.kesci.com/home/competition/5cb80fd312c371002b12355f</link><category>PF</category><category>NLP</category><pubDate>Mon, 06 May 2019</pubDate><description>2019大数据挑战赛（以下简称“大赛”）是在中国高校计算机大赛主办单位的指导下，由清华大学、南开大学与字节跳动公司联合主办，亚马逊AWS提供资源支持以及科赛提供竞赛平台支持，并以企业真实场景和实际数据为基础的高端算法竞赛。大赛面向全球高校在校生开放，旨在提升高校学生对数据分析与处理的算法研究与技术应用能力，探索大数据的核心科学与技术问题，尝试创新大数据技术，推动大数据的产学研用，本次大赛鼓励高校教师参与指导。 预选赛——文本情感分类模型 正式赛题——文本点击率预估（5月26日开赛）</description></item><item><title>CCKS 2019 中文知识图谱问答</title><link>https://www.biendata.com/competition/ccks_2019_6/</link><category>PF/AC</category><category>NLP</category><pubDate>Mon, 06 May 2019</pubDate><description>本评测任务为基于中文知识图谱的自然语言问答，简称CKBQA （Chinese Knowledge Base Question Answering）。即输入一句中文问题，问答系统从给定知识库中选择若干实体或属性值作为该问题的答案。问题均为客观事实型，不包含主观因素。理解并回答问题的过程中可能需要进行实体识别、关系抽取、语义解析等子任务。这些子任务的训练可以使用额外的资源，但是最终的答案必须来自给定的知识库。</description></item><item><title>CCKS 2019 面向金融领域的事件主体抽取</title><link>https://www.biendata.com/competition/ccks_2019_4/</link><category>PF/AC</category><category>NLP</category><pubDate>Mon, 06 May 2019</pubDate><description>本次评测任务的主要目标是从真实的新闻语料中，抽取特定事件类型的主体。即给定一段文本T，和文本所属的事件类型S，从文本T中抽取指定事件类型S的事件主体。</description></item><item><title>OpenEDS Challenge</title><link>https://research.fb.com/programs/openeds-challenge</link><category>PF/AC</category><category>CV</category><pubDate>Mon, 06 May 2019</pubDate><description>In the absence of accurate gaze labels, we propose to advance the state of the art by carefully designing two challenges that combine human annotation of eye features with unlabeled data. These challenges focus on deeper understanding of the distribution underlying human eye state. We invite ML and CV researchers for participation. <a href="https://evalai.cloudcv.org/web/challenges/challenge-page/353">Track-1 Semantic Segmentation challenge</a> <a href="https://evalai.cloudcv.org/web/challenges/challenge-page/354">Track-2 Synthetic Eye Generation challenge</a></description></item><item><title>nocaps</title><link>https://nocaps.org</link><category>PF/AC</category><category>NLP</category><pubDate>Mon, 06 May 2019</pubDate><description>Image captioning models have achieved impressive results on datasets containing limited visual concepts and large amounts of paired image-caption training data. However, if these models are to ever function in the wild, a much larger variety of visual concepts must be learned, ideally from less supervision. To encourage the development of image captioning models that can learn visual concepts from alternative data sources, such as object detection datasets, we present the first large-scale benchmark for this task. Dubbed nocaps, for novel object captioning at scale, our benchmark consists of 166,100 human-generated captions describing 15,100 images from the Open Images validation and test sets. The associated training data consists of COCO image-caption pairs, plus Open Images imagelevel labels and object bounding boxes. Since Open Images contains many more classes than COCO, nearly 400 object classes seen in test images have no or very few associated training captions (hence, nocaps). We extend existing novel object captioning models to establish strong baselines for this benchmark and provide analysis to guide future work on this task.</description></item><item><title>PatchCamelyon</title><link>https://github.com/basveeling/pcam</link><category>PF/AC</category><category>CV</category><pubDate>Mon, 06 May 2019</pubDate><description>The PatchCamelyon benchmark is a new and challenging image classification dataset. It consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annoted with a binary label indicating presence of metastatic tissue. PCam provides a new benchmark for machine learning models: bigger than CIFAR10, smaller than imagenet, trainable on a single GPU.</description></item><item><title>MEDDOCAN (Medical Document Anonymization) task</title><link>https://competitions.codalab.org/competitions/22643</link><category>PF/AC</category><category>NLP</category><pubDate>Sat, 27 Apr 2019</pubDate><description>The MEDDOCAN task will be structured into two sub-tasks: 1) NER offset and entity type classification. 2) Sensitive token detection. The training set comprises 500 clinical cases, and the development and test set 250 clinical cases each.</description></item><item><title>华为算法精英大赛</title><link>http://www.dcjingsai.com/common/cmpt/华为算法精英大赛_竞赛信息.html</link><category>PF</category><category>DM</category><pubDate>Sat, 27 Apr 2019</pubDate><description>“DigiX极客算法精英大赛”（下面简称算法精英赛）是江苏省人工智能学会（JSAI）和华为终端公司联合举办的面向全球高校学子举办的高级别算法竞赛。贴近实战，以丰富的消费者业务场景和数据驱动；涵盖传统机器学习、深度学习以及计算机视觉、自然语言处理等各个业务领域。 赛题一：华为视频会员用户流失预警 赛题二：华为账号用户人口属性预测 赛题三：华为PPS CTR预测</description></item><item><title>5G Broadcast – R&amp;S Engineering Competition 2019</title><link>https://competitions.codalab.org/competitions/22560</link><category>PF</category><category>DM</category><pubDate>Sat, 27 Apr 2019</pubDate><description>In this context, your task is to develop an algorithm (machine learning) to optimize the user experience of the customer (= unsatisfied demand) and to maximize the profit (advertising earnings) of the content provider. </description></item><item><title>The DAVIS Challenge on Video Object Segmentation @ CVPR 2019</title><link>https://davischallenge.org/challenge2019/index.html</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>The <a href="https://davischallenge.org/challenge2019/semisupervised.html">semi-supervised</a>, <a href="https://davischallenge.org/challenge2019/interactive.html">interactive</a> and <a href="https://davischallenge.org/challenge2019/unsupervised.html">unsupervised</a> challenges</description></item><item><title>Apizoom iapr-2019</title><link>https://evalai.cloudcv.org/web/challenges/challenge-page/321/overview</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>Detecting and quantifying the presence of Varroa in a beehive is, therefore, crucial to treat the infection appropriately and as early as possible, and image analysis appears very useful in this problem. For this project, we provide 800 training and 150 validation images with labels.</description></item><item><title>海量光学遥感数据智能处理算法大赛</title><link>http://119.3.218.200:8000</link><category>AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>本次海量光学遥感数据智能处理算法大赛由哈尔滨工业大学（深圳）主办，国防科技创新快速响应小组协办，航天东方红卫星有限公司、中国科学院长春光学精密机械与物理研究所等单位承办，旨在推动海量光学遥感卫星数据处理技术的发展，瞄准在轨应用，推动该技术领域的创新发展，为实现海量遥感数据处理与应用能力的大幅提升提供支撑。 主题一：目标智能检测识别主题 主题二：自主开发应用主题</description></item><item><title>iMaterialist (Fashion) 2019 at FGVC6</title><link>https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>Fine-grained segmentation task for fashion and apparel</description></item><item><title>Urban Region Function Classification</title><link>https://dianshi.baidu.com/competition/30/rule</link><category>PF</category><category>DM/CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>2019 The 5th Baidu &amp; XJTU Big Data Competition And The First IKCEST "One Belt One Road" International Big Data Competition. Build models to classify the functions of urban areas with data of satellite images and user behavior from given geographical areas.</description></item><item><title>2019 AIWIN 5G环境下无人驾驶挑战赛 / Self-driving Car Challenge under 5G Environment</title><link>https://www.kesci.com/home/competition/5cbd8083c7d626002beb280d</link><category>PF/AC</category><category>RL</category><pubDate>Sat, 27 Apr 2019</pubDate><description>Under 5G network environment, Self-driving car faces new opportunities and challenges. International teams are invited to join us at LinGang’s Self-driving car closed test zone to conduct real road test and virtual scene test. 1、无人驾驶 5G应用挑战 / Self-driving Car 5G application challenge 2、自动驾驶算法虚拟场景挑战 / Automatic driving algorithm Virtual scene Challenge</description></item><item><title>The 1st Chinese Audio-Textual Spoken Language Understanding Challenge (CATSLU)</title><link>https://sites.google.com/view/CATSLU/home</link><category>AC</category><category>NLP/SP</category><pubDate>Sat, 27 Apr 2019</pubDate><description>The spoken language understanding (SLU) is a key component of spoken dialogue system (SDS), parsing user's utterances into corresponding semantic concepts. To fully investigate these problems and promote application of spoken dialogue system, we will release a multi-turn task-oriented Chinese spoken dialog dataset and organize the first open, audio-text based Chinese Task Oriented Spoken Language Understanding Challenge. This challenge consists of two sub-challenges: SLU in domain Domain adaptation of SLU</description></item><item><title>The 1st Mandarin Audio-Visual Speech Recognition Challenge (MAVSR)</title><link>http://vipl.ict.ac.cn/homepage/mavsr/index.html</link><category>AC</category><category>CV/SP/NLP</category><pubDate>Sat, 27 Apr 2019</pubDate><description>This challenge aims at exploring the complementarity between visual and acoustic information in real-world speech recognition systems, and will be held at ACM International Conference on Multimodal Interaction (ICMI) 2019. Sub-challenge 1: Closed-set word-level speech recognition Sub-challenge 2: Open-set word-level speech recognition Sub-challenge 3: Visual keyword spotting</description></item><item><title>CCKS 2019 中文短文本的实体链指</title><link>https://www.biendata.com/competition/ccks_2019_el/</link><category>PF/AC</category><category>NLP</category><pubDate>Sat, 27 Apr 2019</pubDate><description>输入文件包括若干行中文短文本。输出文本每一行包括此中文短文本的实体识别与链指结果，需识别出文本中所有mention（包括实体与概念），每个mention包含信息如下：mention在给定知识库中的ID，mention名和在中文短文本中的位置偏移。</description></item><item><title>7th Emotion Recognition in the Wild Challenge (EmotiW)</title><link>https://sites.google.com/view/emotiw2019</link><category>AC</category><category>CV/SP/NLP</category><pubDate>Sat, 27 Apr 2019</pubDate><description>The goal of this challenge is to extend and carry forward the new common platform for evaluation of emotion recognition methods in real-world conditions defined in EmotiW2018 Grand Challenge held at the ACM International Conference on Multimodal Interaction 2018. This year there will be three sub-challenges: Audio-video based emotion recognition sub-challenge (AV) Group-level Cohesion sub-challenge (GC) Engagement prediction in the Wild (EW)</description></item><item><title>Visual Domain Adaptation Challenge (VisDA-2019)</title><link>http://ai.bu.edu/visda-2019/</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>We are pleased to announce the 2019 Visual Domain Adaptation (VisDA2019) Challenge! It is well known that the success of machine learning methods on visual recognition tasks is highly dependent on access to large labeled datasets. Unfortunately, performance often drops significantly when the model is presented with data from a new deployment domain which it did not see in training, a problem known as dataset shift. The VisDA challenge aims to test domain adaptation methods’ ability to transfer source knowledge and adapt it to novel target domains. This challenge includes two tracks: <a href="https://competitions.codalab.org/competitions/22469">Multi-Source Domain Adaptation Challenge</a> <a href="https://competitions.codalab.org/competitions/22470">Semi-Supervised Domain Adaptation</a></description></item><item><title>PAIP 2019 Challenge</title><link>https://paip2019.grand-challenge.org</link><category>PF/AC</category><category>CV</category><pubDate>Sat, 27 Apr 2019</pubDate><description>The goal of the challenge is to evaluate new and existing algorithms for automated detection of liver cancer in whole-slide images (WSIs). There are two tasks and therefore two leaderboards for evaluating the performance of the algorithms. Participants can choose to join both or either tasks according to their interests. Task 1: Liver Cancer Segmentation Task 2: Viable Tumor Burden Estimation</description></item></channel></rss>